---
# IMPORTANT: Change settings here, but DO NOT change the spacing.
# Remove comments and add values where applicable.
# The descriptions below should be self-explanatory

title: "Data Science exam: Question 4 (Netflix)"
#subtitle: "This will appear as Right Header"

documentclass: "elsarticle"

# --------- Thesis title (Optional - set to FALSE by default).
# You can move the details below around as you please.
Thesis_FP: FALSE
# Entry1: "An unbelievable study with a title spanning multiple lines."
# Entry2: "\\textbf{Nico Katzke}" # textbf for bold
# Entry3: "A thesis submitted toward the degree of Doctor of Philosophy"
# Uni_Logo: Tex/Logo.png # Place a logo in the indicated location (from your root, e.g. defaults to ~/Tex/Logo.png) and uncomment this line. Leave uncommented for no image
# Logo_width: 0.3 # If using a logo - use this to set width (size) of image
# Entry4: "Under the supervision of: \\vfill Prof. Joe Smith and Dr. Frank Smith"
# Entry5: "Stellenbosch University"
# Entry6: April 2020
# Entry7:
# Entry8:

# --------- Front Page
# Comment: ----- Follow this pattern for up to 5 authors
AddTitle: TRUE # Use FALSE when submitting to peer reviewed platform. This will remove author names.
Author1: "Erik Valentin Schulte" # First Author - note the thanks message displayed as an italic footnote of first page.
Ref1: "Stellenbosch University, South Africa" # First Author's Affiliation
Email1: "26802325\\@sun.ac.su" # First Author's Email address

# Author2: "John Smith"
# Ref2: "Some other Institution, Cape Town, South Africa"
# Email2: "John\\@gmail.com"
# CommonAffiliation_12: TRUE # If Author 1 and 2 have a common affiliation. Works with _13, _23, etc.
# 
# Author3: "John Doe"
# Email3: "Joe\\@gmail.com"

CorrespAuthor_1: TRUE  # If corresponding author is author 3, e.g., use CorrespAuthor_3: TRUE

# Comment out below to remove both. JEL Codes only given if keywords also given.
# keywords: "Multivariate GARCH \\sep Kalman Filter \\sep Copula" # Use \\sep to separate
# JELCodes: "L250 \\sep L100"

# ----- Manage headers and footers:
#BottomLFooter: $Title$
#BottomCFooter:
#TopLHeader: \leftmark # Adds section name at topleft. Remove comment to add it.
BottomRFooter: "\\footnotesize Page \\thepage" # Add a '#' before this line to remove footer.
addtoprule: TRUE
addfootrule: TRUE               # Use if footers added. Add '#' to remove line.

# --------- page margins:
margin: 2.3 # Sides
bottom: 2 # bottom
top: 2.5 # Top
HardSet_layout: TRUE # Hard-set the spacing of words in your document. This will stop LaTeX squashing text to fit on pages, e.g.
# This is done by hard-setting the spacing dimensions. Set to FALSE if you want LaTeX to optimize this for your paper.

# --------- Line numbers
linenumbers: FALSE # Used when submitting to journal

# ---------- References settings:
# You can download cls format here: https://www.zotero.org/ - simply search for your institution. You can also edit and save cls formats here: https://editor.citationstyles.org/about/
# Hit download, store it in Tex/ folder, and change reference below - easy.
bibliography: Tex/ref.bib       # Do not edit: Keep this naming convention and location.
csl: Tex/harvard-stellenbosch-university.csl # referencing format used.
# By default, the bibliography only displays the cited references. If you want to change this, you can comment out one of the following:
#nocite: '@*' # Add all items in bibliography, whether cited or not
# nocite: |  # add specific references that aren't cited
#  @grinold2000
#  @Someoneelse2010

# ---------- General:
RemovePreprintSubmittedTo: TRUE  # Removes the 'preprint submitted to...' at bottom of titlepage
Journal: "Journal of Finance"   # Journal that the paper will be submitting to, if RemovePreprintSubmittedTo is set to TRUE.
toc: FALSE                       # Add a table of contents
numbersections: TRUE             # Should sections (and thus figures and tables) be numbered?
fontsize: 11pt                  # Set fontsize
linestretch: 1.2                # Set distance between lines.
link-citations: TRUE            # This creates dynamic links to the papers in reference list.

### Adding additional latex packages:
# header-includes:
#    - \usepackage{colortbl} # Add additional packages here.

output:
  pdf_document:
    keep_tex: TRUE
    template: Tex/TexDefault.txt
    fig_width: 3.5 # Adjust default figure sizes. This can also be done in the chunks of the text.
    fig_height: 3.5
abstract: |
  x.
---
<!-- First: Set your default preferences for chunk options: -->

<!-- If you want a chunk's code to be printed, set echo = TRUE. message = FALSE stops R printing ugly package loading details in your final paper too. I also suggest setting warning = FALSE and checking for warnings in R, else you might find ugly warnings in your paper. -->

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE, fig.width = 6, fig.height = 5, fig.pos="H", fig.pos = 'H')

if(!require("tidyverse")) install.packages("tidyverse")
library(tidyverse)

list.files('code/', full.names = T, recursive = T) %>% as.list() %>% walk(~source(.))

datcolat <- Data_Collating(Datroot = "data/netflix/")  #changed to a small d

library(readr)
titles <- read_csv("~/ownCloud/Uni Göttingen/Stellenbosch University/Data Science Methods/26802325/Solution/Q4/data/netflix/titles.csv")
credits <- read_csv("~/ownCloud/Uni Göttingen/Stellenbosch University/Data Science Methods/26802325/Solution/Q4/data/netflix/credits.csv")

#now matched id of both ....
datasetnetflix <- merge(titles, credits, by="id")
```


<!-- ############################## -->
<!-- # Start Writing here: -->
<!-- ############################## -->

# Introduction \label{Introduction}

Both datasets have a common identifier by which it can be knitted. I merge the two dataset and perform the following analysis. First, I present a table with some summary statistic about the newly merged dataset.


```{r}
# summary(datasetnetflix)
# summary
# summary
library(stargazer)

datasetnetflix |> select(release_year, runtime, seasons, imdb_score, imdb_votes, tmdb_popularity, tmdb_score)|> stargazer(type = "text")
```

Using the stargazer function we can see that the earliest movie was released in 1953 and the latest movies in 2022, while the medians of movies releases is 2018. The maximum runtime is 251 minutes and the mean run time for each movie is 96 minutes. 

The range of the seasons of the netflix data is 1 to 42.

IMDB scores range from 1.5 to 9.5, the average rating of all the movies contained in the dataset is 6.466.

For the tmb score, there the rating scale ranges from 1 to 10 and the average rating is slighly higher with 6.685.

# What are good movies?

```{r}
#data wrangling for plot 1
directors <- subset(datasetnetflix, role == "DIRECTOR")
#this gives a dataframe with movies with directors that got a rating of both scores above 8
topdirector <- subset(datasetnetflix, role == "DIRECTOR" & imdb_score >= 8.4 & tmdb_score >= 8.4)
```
First, I looks at specific directors that did well, specifically those who got ratings from the Internet Movie Database and the TMDB score of higher than 8.4. 8.4 was choosen arbitrarily to have just the right amount of observations in the graph. 

```{r,  warning =  FALSE, fig.align = 'center', fig.cap = "Good movies.\\label{Figure1}", fig.ext = 'png', fig.height = 5, fig.width = 7}
#plot the scores by director, calculate the average score by direcor
#runtime by genre
#rating by genre.

  whatworks <-
    plot1_netflix(topdirector, xaxis_size = 5, xaxis_rows = 3)
    
whatworks
```

We can see from graph 1 that there are a few directors that did really well. There is also a lot of variation in the runtime from very short shows with less than 30 minutes by the Director He Xiaofeng or rather long shows by Shin Won-ho which take more than 150 minutes. More of the good ratings are allocated towards shows rather than movies. I would recommend my superiors into looking into the works of the Directors I found. 

# What are bad movies?
```{r}
#data wrangling bad movies
bad_movies <- subset(datasetnetflix, imdb_score <= 4.4 & tmdb_score <= 4.4)
#distinct(bad_movies)
#bad_movies %>% group_by(id) %>% summarise_at(vars())

```
The data are also rich in what my superiors should not do. They should be careful with works that were produced by single countries only. There, seems to be especially bad movies and shows coming from India and the US, since the cumulative runtime exceeds 25000 hourse for India and 15.000hours for the US.. However, these are most likely also two very high producing countries. It is also apparent from the bad movie data that most bad movies do not have an age certificaiton. Most are available for India (PG-13) and the US (R) and Japan (TV-PG).


```{r,  warning =  FALSE, fig.align = 'center', fig.cap = "Bad movies.\\label{Figure2}", fig.ext = 'png', fig.height = 5, fig.width = 7}
#bad movies
 whatworksnot <-
    plot2_netflix(bad_movies, xaxis_size = 5, xaxis_rows = 3)
    
whatworksnot

```

Looking at the graph with the bad movies with low ratings we can see where they were produced. Interestingly, the worst movies were produced by single countries and not by co-production.






